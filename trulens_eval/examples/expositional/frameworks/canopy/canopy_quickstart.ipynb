{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruLens-Canopy Quickstart\n",
    "\n",
    " Canopy is an open-source framework and context engine built on top of the Pinecone vector database so you can build and host your own production-ready chat assistant at any scale. By integrating TruLens into your Canopy assistant, you can quickly iterate on and gain confidence in the quality of your chat assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU canopy-sdk trulens-eval cohere ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "assert numpy.__version__ >= \"1.26\", \"Numpy version did not updated, if you are working on Colab please restart the session.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"YOUR_PINECONE_API_KEY\"  # take free trial key from https://app.pinecone.io/\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # take free trial key from https://platform.openai.com/api-keys\n",
    "os.environ[\"CO_API_KEY\"] = \"YOUR_COHERE_API_KEY\"  # take free trial key from https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.environ[\"PINECONE_API_KEY\"] != \"YOUR_PINECONE_API_KEY\", \"please provide PINECONE API key\"\n",
    "assert os.environ[\"OPENAI_API_KEY\"] != \"YOUR_OPENAI_API_KEY\", \"please provide OpenAI API key\"\n",
    "assert os.environ[\"CO_API_KEY\"] != \"YOUR_COHERE_API_KEY\", \"please provide Cohere API key\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Downloading Pinecone's documentation as data to ingest to our Canopy chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728aeea1-1dcf-5d0a-91f2-ecccd4dd4272</td>\n",
       "      <td># Scale indexes\\n\\n[Suggest Edits](/edit/scali...</td>\n",
       "      <td>https://docs.pinecone.io/docs/scaling-indexes</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'scaling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f19f269-171f-5556-93f3-a2d7eabbe50f</td>\n",
       "      <td># Understanding organizations\\n\\n[Suggest Edit...</td>\n",
       "      <td>https://docs.pinecone.io/docs/organizations</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'organiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2a71cb3-5148-5090-86d5-7f4156edd7cf</td>\n",
       "      <td># Manage datasets\\n\\n[Suggest Edits](/edit/dat...</td>\n",
       "      <td>https://docs.pinecone.io/docs/datasets</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'datasets'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1dafe68a-2e78-57f7-a97a-93e043462196</td>\n",
       "      <td># Architecture\\n\\n[Suggest Edits](/edit/archit...</td>\n",
       "      <td>https://docs.pinecone.io/docs/architecture</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd</td>\n",
       "      <td># Moving to production\\n\\n[Suggest Edits](/edi...</td>\n",
       "      <td>https://docs.pinecone.io/docs/moving-to-produc...</td>\n",
       "      <td>{'created_at': '2023_10_25', 'title': 'moving-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  728aeea1-1dcf-5d0a-91f2-ecccd4dd4272  \\\n",
       "1  2f19f269-171f-5556-93f3-a2d7eabbe50f   \n",
       "2  b2a71cb3-5148-5090-86d5-7f4156edd7cf   \n",
       "3  1dafe68a-2e78-57f7-a97a-93e043462196   \n",
       "4  8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd   \n",
       "\n",
       "                                                text   \n",
       "0  # Scale indexes\\n\\n[Suggest Edits](/edit/scali...  \\\n",
       "1  # Understanding organizations\\n\\n[Suggest Edit...   \n",
       "2  # Manage datasets\\n\\n[Suggest Edits](/edit/dat...   \n",
       "3  # Architecture\\n\\n[Suggest Edits](/edit/archit...   \n",
       "4  # Moving to production\\n\\n[Suggest Edits](/edi...   \n",
       "\n",
       "                                              source   \n",
       "0      https://docs.pinecone.io/docs/scaling-indexes  \\\n",
       "1        https://docs.pinecone.io/docs/organizations   \n",
       "2             https://docs.pinecone.io/docs/datasets   \n",
       "3         https://docs.pinecone.io/docs/architecture   \n",
       "4  https://docs.pinecone.io/docs/moving-to-produc...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'created_at': '2023_10_25', 'title': 'scaling...  \n",
       "1  {'created_at': '2023_10_25', 'title': 'organiz...  \n",
       "2  {'created_at': '2023_10_25', 'title': 'datasets'}  \n",
       "3  {'created_at': '2023_10_25', 'title': 'archite...  \n",
       "4  {'created_at': '2023_10_25', 'title': 'moving-...  "
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_parquet(\"https://storage.googleapis.com/pinecone-datasets-dev/pinecone_docs_ada-002/raw/file1.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Limits\n",
      "This is a summary of current Pinecone limitations. For many of these, there is a workaround or we're working on increasing the limits.\n",
      "\n",
      "## Upserts\n",
      "\n",
      "Max vector dimensionality is 20,000.\n",
      "\n",
      "Max size for an upsert request is 2MB. Recommended upsert limit is 100 vectors per request.\n",
      "\n",
      "Vectors may not be visible to queries immediately after upserting. You can check if the vectors were indexed by looking at the total with `describe_index_stats()`, although this method may not work if the index has multiple replicas. Pinecone is eventually consistent.\n",
      "\n",
      "Pinecone supports sparse vector values of sizes up to 1000 non-zero values.\n",
      "\n",
      "## Queries\n",
      "\n",
      "Max value for `top_k`, the number of results to return, is 10,000. Max value for `top_k` for queries with `include_metadata=True` or `include_data=True` is 1,000.\n",
      "\n",
      "......\n",
      "source:  https://docs.pinecone.io/docs/limits\n"
     ]
    }
   ],
   "source": [
    "print(data[\"text\"][50][:847].replace(\"\\n\\n\", \"\\n\").replace(\"[Suggest Edits](/edit/limits)\", \"\") + \"\\n......\")\n",
    "print(\"source: \", data[\"source\"][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ' world', '!']"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from canopy.tokenizer import Tokenizer\n",
    "Tokenizer.initialize()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.tokenize(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa11cca4706462fa563c109f39dfee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from canopy.knowledge_base import KnowledgeBase\n",
    "from canopy.models.data_models import Document\n",
    "from canopy.knowledge_base import list_canopy_indexes\n",
    "\n",
    "index_name = \"pinecone-docs\"\n",
    "\n",
    "kb = KnowledgeBase(index_name)\n",
    "\n",
    "if not any(name.endswith(index_name) for name in list_canopy_indexes()):\n",
    "    kb.create_canopy_index()\n",
    "\n",
    "kb.connect()\n",
    "\n",
    "documents = [Document(**row) for _, row in data.iterrows()]\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(documents), batch_size)):\n",
    "    kb.upsert(documents[i: i+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create context and chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canopy.models.data_models import Query\n",
    "from canopy.context_engine import ContextEngine\n",
    "context_engine = ContextEngine(kb)\n",
    "\n",
    "from canopy.chat_engine import ChatEngine\n",
    "chat_engine = ChatEngine(context_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument static methods used by engine with TruLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "from canopy.context_engine import ContextEngine\n",
    "instrument.method(ContextEngine, \"query\")\n",
    "\n",
    "from canopy.chat_engine import ChatEngine\n",
    "instrument.method(ChatEngine, \"chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feedback functions using instrumented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru(database_redact_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.app.chat.rets.choices[0].message.content .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.app.chat.args.messages[0].content .\n",
      "✅ In Answer Relevance, input response will be set to __record__.app.chat.rets.choices[0].message.content .\n",
      "✅ In Context Relevance, input question will be set to __record__.app.chat.args.messages[0].content .\n",
      "✅ In Context Relevance, input statement will be set to __record__.app.context_engine.query.rets.content.root[:].snippets[:].text .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "fopenai = fOpenAI()\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=fopenai)\n",
    "\n",
    "intput = Select.RecordCalls.chat.args.messages[0].content\n",
    "context = Select.RecordCalls.context_engine.query.rets.content.root[:].snippets[:].text\n",
    "output = Select.RecordCalls.chat.rets.choices[0].message.content\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\", higher_is_better=True)\n",
    "    .on(context.collect())\n",
    "    .on(output)\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = (\n",
    "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\", higher_is_better=True)\n",
    "    .on(intput)\n",
    "    .on(output)\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\", higher_is_better=True)\n",
    "    .on(intput)\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create recorded app and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function <function ContextEngine.query at 0x13a715630> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14b157ac0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function ChatEngine.chat at 0x13a587eb0> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14b157ac0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function QueryGenerator.generate at 0x13a7157e0> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14b157ac0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "\n",
    "app_id = \"canopy default\"\n",
    "tru_recorder = TruCustomApp(chat_engine, app_id=app_id, feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='What is the maximum dimension for a dense vector in Pinecone?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n",
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='How can you get started with Pinecone and TruLens?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n",
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='What is the the maximum top-k for a query to Pinecone?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n"
     ]
    }
   ],
   "source": [
    "from canopy.models.data_models import UserMessage\n",
    "\n",
    "queries = [\n",
    "    [UserMessage(content=\"What is the maximum dimension for a dense vector in Pinecone?\")],\n",
    "    [UserMessage(content=\"How can you get started with Pinecone and TruLens?\")],\n",
    "    [UserMessage(content=\"What is the the maximum top-k for a query to Pinecone?\")]\n",
    "]\n",
    "\n",
    "answers = []\n",
    "\n",
    "for query in queries:\n",
    "    with tru_recorder as recording:\n",
    "        response = chat_engine.chat(query)\n",
    "        answers.append(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got the wrong answer, the limits for sparse vectors instead of dense vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the maximum dimension for a dense vector in Pinecone?\n",
      "\n",
      "The maximum dimension for a dense vector in Pinecone is over 4 billion dimensions.\n"
     ]
    }
   ],
   "source": [
    "print(queries[0][0].content + \"\\n\")\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canopy default</th>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Context Relevance  Groundedness  Answer Relevance  latency   \n",
       "app_id                                                                       \n",
       "canopy default           0.806667           0.5          0.966667      4.0  \\\n",
       "\n",
       "                total_cost  \n",
       "app_id                      \n",
       "canopy default    0.002296  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[app_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Canopy with Cohere reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canopy.knowledge_base.reranker.cohere import CohereReranker\n",
    "\n",
    "kb = KnowledgeBase(index_name=index_name, reranker=CohereReranker(top_n=3), default_top_k=30)\n",
    "kb.connect()\n",
    "\n",
    "reranker_chat_engine = ChatEngine(ContextEngine(kb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function <function ContextEngine.query at 0x13a715630> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14c878ca0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function ChatEngine.chat at 0x13a587eb0> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14c878ca0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function QueryGenerator.generate at 0x13a7157e0> was not found during instrumentation walk. Make sure it is accessible by traversing app <canopy.chat_engine.chat_engine.ChatEngine object at 0x14c878ca0> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='What is the maximum dimension for a dense vector in Pinecone?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n",
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='How can you get started with Pinecone and TruLens?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n",
      "Unsure what the main input string is for the call to chat with args [[UserMessage(role=<Role.USER: 'user'>, content='What is the the maximum top-k for a query to Pinecone?')]].\n",
      "Unsure what the main output string is for the call to chat with return type <class 'canopy.models.api_models.ChatResponse'>.\n"
     ]
    }
   ],
   "source": [
    "reranking_app_id = \"canopy_reranking\"\n",
    "reranking_tru_recorder = TruCustomApp(reranker_chat_engine,\n",
    "                                      app_id=reranking_app_id,\n",
    "                                      feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])\n",
    "\n",
    "answers = []\n",
    "\n",
    "for query in queries:\n",
    "    with reranking_tru_recorder as recording:\n",
    "        answers.append(reranker_chat_engine.chat(query).choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reranking we get the right answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the maximum dimension for a dense vector in Pinecone?\n",
      "\n",
      "The maximum dimension for a dense vector in Pinecone is 20,000. (Source: https://docs.pinecone.io/docs/limits)\n"
     ]
    }
   ],
   "source": [
    "print(queries[0][0].content + \"\\n\")\n",
    "print(answers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the effect of reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canopy_reranking</th>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canopy default</th>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Context Relevance  Groundedness  Answer Relevance  latency   \n",
       "app_id                                                                         \n",
       "canopy_reranking           0.830556      0.833333          0.966667      4.0  \\\n",
       "canopy default             0.806667      0.500000          0.966667      4.0   \n",
       "\n",
       "                  total_cost  \n",
       "app_id                        \n",
       "canopy_reranking    0.002265  \n",
       "canopy default      0.002296  "
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[app_id, reranking_app_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b49ef6d0b3ca0fd6117ebbca48c3d697c422d5d25bd8bdbbbbafb3db0f51ca63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
